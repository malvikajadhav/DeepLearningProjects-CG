{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io, color\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /home/jadhav.m/.local/lib/python3.9/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/jadhav.m/.local/lib/python3.9/site-packages (from opencv-python) (1.23.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: scikit-image in /home/jadhav.m/.local/lib/python3.9/site-packages (0.19.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (1.23.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-image) (2.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (2022.10.10)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (1.8.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (2.19.3)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/jadhav.m/.local/lib/python3.9/site-packages (from networkx>=2.2->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/jadhav.m/.local/lib/python3.9/site-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_dir = os.path.join('./Dataset/face_images/face_images/train/face_images')\n",
    "img_test_dir = os.path.join('./Dataset/face_images/face_images/test/face_images')\n",
    "aug_train_dir = os.path.join('./Dataset/augment_images')\n",
    "lab_train_dir = os.path.join('./Dataset/lab_images')\n",
    "lab_test_dir = os.path.join('./Dataset/lab_images/test')\n",
    "l_train_dir = os.path.join('./Dataset/l_images')\n",
    "l_test_dir = os.path.join('./Dataset/l_images/test')\n",
    "a_train_dir = os.path.join('./Dataset/a_images/')\n",
    "a_test_dir = os.path.join('./Dataset/a_images/test')\n",
    "b_train_dir = os.path.join('./Dataset/b_images/')\n",
    "b_test_dir = os.path.join('./Dataset/b_images/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_a_train = glob.glob(os.path.join(a_train_dir,\"*.jpg\"))\n",
    "image_list_a_train.sort()\n",
    "image_list_b_train = glob.glob(os.path.join(b_train_dir,\"*.jpg\"))\n",
    "image_list_b_train.sort()\n",
    "input_image_list_train = glob.glob(os.path.join(l_train_dir,\"*.jpg\"))\n",
    "input_image_list_train.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.annotations = input_image_list_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path =  input_image_list_train[index]\n",
    "        image = io.imread(img_path)\n",
    "        a_path = image_list_a_train[index]\n",
    "        a = io.imread(a_path)\n",
    "        b_path = image_list_b_train[index]\n",
    "        b = io.imread(b_path)\n",
    "        a = self.transform(a)\n",
    "        b = self.transform(b)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return (image, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-7\n",
    "batch_size = 10\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TrainDataset(\n",
    "    csv_file=\"exp_input.csv\",\n",
    "    root_dir=\"CAP5404/l_images\",\n",
    "), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_a_test = glob.glob(os.path.join(a_test_dir,\"*.jpg\"))\n",
    "image_list_a_test.sort()\n",
    "image_list_b_test = glob.glob(os.path.join(b_test_dir,\"*.jpg\"))\n",
    "image_list_b_test.sort()\n",
    "input_image_list_test = glob.glob(os.path.join(l_test_dir,\"*.jpg\"))\n",
    "input_image_list_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.annotations = input_image_list_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path =  input_image_list_test[index]\n",
    "        image = io.imread(img_path)\n",
    "        a_path = image_list_a_test[index]\n",
    "        a = io.imread(a_path)\n",
    "        b_path = image_list_b_test[index]\n",
    "        b = io.imread(b_path)\n",
    "        a = self.transform(a)\n",
    "        b = self.transform(b)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return (image, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-7\n",
    "batch_size = 10\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader( TestDataset(\n",
    "    csv_file=\"exp_input.csv\",\n",
    "    root_dir=\"CAP5404/l_images\",\n",
    "), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(nn.Conv2d(1,3,kernel_size=2, padding=0,stride=2),\n",
    "                                 nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(32),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(16),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(16, 9, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(9),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(9, 2, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2))\n",
    "    \n",
    "                                \n",
    "                                 \n",
    "    def forward(self, input):\n",
    "        output = self.cnn(input)\n",
    "        #         mean_chrominance = self.regressor(output)\n",
    "\n",
    "        return  output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "start = dt.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train MSE is 0.005564737640198372\n",
      "Average Test MSE is 0.0008029561029616161\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "import torchvision.transforms as transforms\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "Train_losses = []\n",
    "Test_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx,(data, a , b) in enumerate(train_loader):\n",
    "        #img_path =  input_image_list[index] \n",
    "        data = data\n",
    "        target_a = a\n",
    "        target_b = b\n",
    "        target = torch.cat((a, b), 1)\n",
    "        # forward\n",
    "        pred = model(data)\n",
    "        loss_val = loss(pred, target)\n",
    "\n",
    "        Train_losses.append(loss_val.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_val.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_idx,(data, a , b) in enumerate(test_loader):\n",
    "        #img_path =  input_image_list[index] \n",
    "        data = data\n",
    "        target_a = a\n",
    "        target_b = b\n",
    "        target = torch.cat((a, b), 1)\n",
    "        # forward\n",
    "        pred = model(data)\n",
    "        \n",
    "        loss_val = loss(pred, target)\n",
    "\n",
    "        Test_losses.append(loss_val.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_val.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "print(f\"Average Train MSE is {sum(Train_losses)/len(Train_losses)}\")\n",
    "print(f\"Average Test MSE is {sum(Test_losses)/len(Test_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_secs = (dt.now() - start).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'colorizer_cpu_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 32 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 8 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1222 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 144 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 3617 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 28 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 3785 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 6847 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1589 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 9 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 5323 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 181 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 2048 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 2336 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1491 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1663 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1821 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1283 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 3528 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 5 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 2361 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 479 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 1197 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 7380 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 24 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 942 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 51 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 4278 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/jadhav.m/.local/lib/python3.9/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 7 pixels\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx,(data, a , b) in enumerate(test_loader):\n",
    "        #img_path =  input_image_list[index] \n",
    "        data = data\n",
    "        target_a = a\n",
    "        target_b = b\n",
    "        # forward\n",
    "        pred = model(data)\n",
    "        save_predict_image(pred, data, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n",
    "    '''Show/save rgb image from grayscale and ab channels\n",
    "    Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n",
    "    plt.clf() # clear matplotlib \n",
    "    color_image = torch.cat((grayscale_input, ab_input), 0).detach().numpy() # combine channels\n",
    "    color_image = color_image + 1\n",
    "    color_image = color_image - color_image.min()\n",
    "    color_image = color_image / (color_image.max() - color_image.min())\n",
    "    color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
    "    color_image = color.lab2rgb(color_image.astype(np.float64))\n",
    "    grayscale_input = grayscale_input.squeeze().numpy()\n",
    "    plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path + \"grayscale\", save_name), cmap='gray')\n",
    "    plt.imsave(arr=color_image, fname='{}{}'.format(save_path, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predict_image(pred, data, batch_idx):\n",
    "    for i in range(len(data)):\n",
    "        name = str(batch_idx) + \" \" + str(i)\n",
    "        to_rgb(data[i], pred[i], save_path = \"./predicted_images_cpu/\", save_name = f\"{name}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
