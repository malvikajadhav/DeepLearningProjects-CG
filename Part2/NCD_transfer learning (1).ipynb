{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io, color\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /home/jadhav.m/.local/lib/python3.9/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/jadhav.m/.local/lib/python3.9/site-packages (from opencv-python) (1.23.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: scikit-image in /home/jadhav.m/.local/lib/python3.9/site-packages (0.19.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (1.8.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-image) (2.5.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (2022.10.10)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (2.19.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/jadhav.m/.local/lib/python3.9/site-packages (from scikit-image) (1.23.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/jadhav.m/.local/lib/python3.9/site-packages (from networkx>=2.2->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/jadhav.m/.local/lib/python3.9/site-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-gpu (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/home/jadhav.m/.local/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(nn.Conv2d(1,3,kernel_size=2, padding=0,stride=2),\n",
    "                                 nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(32),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(16),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(16, 9, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.BatchNorm2d(9),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(9, 2, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Upsample(scale_factor=2))\n",
    "    \n",
    "                                \n",
    "                                 \n",
    "    def forward(self, input):\n",
    "        output = self.cnn(input)\n",
    "        #         mean_chrominance = self.regressor(output)\n",
    "\n",
    "        return  output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (16): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (20): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (24): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "    (27): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (28): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU()\n",
       "    (31): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (32): Conv2d(9, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU()\n",
       "    (34): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = CNN()\n",
    "model.to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load(\"./colorizer_250.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-7\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ssims = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'Apple',\n",
       " 'Banana',\n",
       " 'Brinjal',\n",
       " 'Broccoli',\n",
       " 'CapsicumGreen',\n",
       " 'Carrot',\n",
       " 'Cherry',\n",
       " 'ChilliGreen',\n",
       " 'Corn',\n",
       " 'Cucumber',\n",
       " 'LadyFinger',\n",
       " 'Lemon',\n",
       " 'Orange',\n",
       " 'Peach',\n",
       " 'Pear',\n",
       " 'Plum',\n",
       " 'Pomegranate',\n",
       " 'Potato',\n",
       " 'Strawberry',\n",
       " 'Tomato']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(\"./Dataset/ColorfulOriginal\")\n",
    "classes.sort()\n",
    "classes[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Apple)Average SSIM = <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncd_test = glob.glob(os.path.join(\"./Dataset/Gray/Banana/\",\"*.jpg\"))\n",
    "ncd_test.sort()\n",
    "ncd_original = glob.glob(os.path.join(\"./Dataset/ColorfulOriginal/Banana/\",\"*.jpg\"))\n",
    "ncd_original.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCDTestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.annotations = ncd_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = ncd_test[index]\n",
    "        img_path_o = ncd_original[index]\n",
    "        T = transforms.Resize((128, 128))\n",
    "        image = Image.open(img_path)\n",
    "        image_o = Image.open(img_path_o)\n",
    "        image = T(image)\n",
    "        image_o = T(image_o)\n",
    "        image = self.transform(image)\n",
    "        image_o = self.transform(image_o)\n",
    "        return (image, image_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncd_test_loader = DataLoader(NCDTestDataset(), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for b, (image, image_o) in enumerate(ncd_test_loader):\n",
    "    image = image.to(device = device)\n",
    "    pred = model(image)\n",
    "    \n",
    "    save_predict_image_ncd(pred.cpu(), image.cpu(), b, image_o.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb_ncd(grayscale_input, ab_input, original, save_path=None, save_name=None):\n",
    "    '''Show/save rgb image from grayscale and ab channels\n",
    "    Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n",
    "    plt.clf() # clear matplotlib \n",
    "    color_image = torch.cat((grayscale_input, ab_input), 0).detach().numpy() # combine channels\n",
    "    color_image = color_image + 1\n",
    "    color_image = color_image - color_image.min()\n",
    "    color_image = color_image / (color_image.max() - color_image.min())\n",
    "    color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
    "    color_image = color.lab2rgb(color_image.astype(np.float64))\n",
    "    grayscale_input = grayscale_input.squeeze().numpy()\n",
    "    original = original.numpy()\n",
    "    original = original.transpose()\n",
    "\n",
    "    #plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path + \"grayscale\", save_name), cmap='gray')\n",
    "    plt.imsave(arr=original, fname='{}{}'.format(save_path, save_name))\n",
    "    plt.imsave(arr=color_image, fname='{}{}'.format(save_path, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predict_image_ncd(pred, data, batch_idx, image_o):\n",
    "    for i in range(len(data)):\n",
    "        name = str(batch_idx) + \" \" + str(i)\n",
    "        to_rgb_ncd(data[i], pred[i], image_o[i], save_path = \"./ncd_predicted_images/Banana/\", save_name = f\"{name}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = os.listdir(\"./Dataset/ColorfulOriginal/Banana\")\n",
    "lists.sort()\n",
    "pred_list = os.listdir(\"./ncd_predicted_images/Banana\")\n",
    "pred_list.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './ncd_predicted_images/Banana/.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/51281488/ipykernel_62210/1420956214.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./ncd_predicted_images/Banana\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3091\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3092\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3093\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './ncd_predicted_images/Banana/.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "transform = T.Resize((128,128))\n",
    "ssim_vals = []\n",
    "for i in range(len(pred_list)):\n",
    "    a = Image.open(os.path.join(\"./Dataset/ColorfulOriginal/Banana\",lists[i]))\n",
    "    a = transform(a)\n",
    "    a = np.array(a)\n",
    "    b = Image.open(os.path.join(\"./ncd_predicted_images/Banana\",pred_list[i]))\n",
    "    b = transform(b)\n",
    "    b = np.array(b) \n",
    "    ssim_vals.append(ssim(a, b, channel_axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssim_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Carrot\"] = ssim_vals\n",
    "df_final = pd.concat([df,df_final], ignore_index=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns = [\"Tomato\",\"Strawberry\",\"Potato\",\"Pomegranate\",\"Plum\",\"Pear\",\"Peach\",\"Orange\",\"Lemon\",\"LadyFinger\",\"Cucumber\",\"Corn\",\"ChilliGreen\",\"Cherry\",\"Carrot\",\"CapsicumGreen\",\"Broccoli\",\"Brinjal\",\"Apple\",\"Banana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tomato</th>\n",
       "      <th>Strawberry</th>\n",
       "      <th>Potato</th>\n",
       "      <th>Pomegranate</th>\n",
       "      <th>Plum</th>\n",
       "      <th>Pear</th>\n",
       "      <th>Peach</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Lemon</th>\n",
       "      <th>LadyFinger</th>\n",
       "      <th>Cucumber</th>\n",
       "      <th>Corn</th>\n",
       "      <th>ChilliGreen</th>\n",
       "      <th>Cherry</th>\n",
       "      <th>Carrot</th>\n",
       "      <th>CapsicumGreen</th>\n",
       "      <th>Broccoli</th>\n",
       "      <th>Brinjal</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Banana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341002</td>\n",
       "      <td>0.315255</td>\n",
       "      <td>0.375852</td>\n",
       "      <td>0.292136</td>\n",
       "      <td>0.226278</td>\n",
       "      <td>0.804610</td>\n",
       "      <td>0.394865</td>\n",
       "      <td>0.309855</td>\n",
       "      <td>0.370026</td>\n",
       "      <td>0.237663</td>\n",
       "      <td>0.507296</td>\n",
       "      <td>0.162051</td>\n",
       "      <td>0.491359</td>\n",
       "      <td>0.250759</td>\n",
       "      <td>0.440752</td>\n",
       "      <td>0.580714</td>\n",
       "      <td>0.348162</td>\n",
       "      <td>0.383197</td>\n",
       "      <td>0.525455</td>\n",
       "      <td>0.534317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537191</td>\n",
       "      <td>0.458828</td>\n",
       "      <td>0.452231</td>\n",
       "      <td>0.318448</td>\n",
       "      <td>0.311758</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.416896</td>\n",
       "      <td>0.806128</td>\n",
       "      <td>0.385563</td>\n",
       "      <td>0.552115</td>\n",
       "      <td>0.500968</td>\n",
       "      <td>0.252959</td>\n",
       "      <td>0.410454</td>\n",
       "      <td>0.264638</td>\n",
       "      <td>0.461590</td>\n",
       "      <td>0.356402</td>\n",
       "      <td>0.362346</td>\n",
       "      <td>0.416804</td>\n",
       "      <td>0.444392</td>\n",
       "      <td>0.520542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.386674</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>0.563667</td>\n",
       "      <td>0.379463</td>\n",
       "      <td>0.572559</td>\n",
       "      <td>0.469921</td>\n",
       "      <td>0.362688</td>\n",
       "      <td>0.276406</td>\n",
       "      <td>0.383648</td>\n",
       "      <td>0.456395</td>\n",
       "      <td>0.460107</td>\n",
       "      <td>0.364422</td>\n",
       "      <td>0.535779</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.552798</td>\n",
       "      <td>0.535719</td>\n",
       "      <td>0.250374</td>\n",
       "      <td>0.461672</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.666670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.335456</td>\n",
       "      <td>0.443824</td>\n",
       "      <td>0.618811</td>\n",
       "      <td>0.360106</td>\n",
       "      <td>0.405951</td>\n",
       "      <td>0.306371</td>\n",
       "      <td>0.328475</td>\n",
       "      <td>0.465907</td>\n",
       "      <td>0.414677</td>\n",
       "      <td>0.951618</td>\n",
       "      <td>0.457385</td>\n",
       "      <td>0.420880</td>\n",
       "      <td>0.565803</td>\n",
       "      <td>0.302666</td>\n",
       "      <td>0.620328</td>\n",
       "      <td>0.502862</td>\n",
       "      <td>0.269386</td>\n",
       "      <td>0.312841</td>\n",
       "      <td>0.373471</td>\n",
       "      <td>0.384275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372083</td>\n",
       "      <td>0.387127</td>\n",
       "      <td>0.599096</td>\n",
       "      <td>0.349777</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.428940</td>\n",
       "      <td>0.441945</td>\n",
       "      <td>0.455679</td>\n",
       "      <td>0.711824</td>\n",
       "      <td>0.399981</td>\n",
       "      <td>0.255603</td>\n",
       "      <td>0.297288</td>\n",
       "      <td>0.290908</td>\n",
       "      <td>0.653533</td>\n",
       "      <td>0.509162</td>\n",
       "      <td>0.321159</td>\n",
       "      <td>0.353953</td>\n",
       "      <td>0.288864</td>\n",
       "      <td>0.592705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tomato  Strawberry    Potato  Pomegranate      Plum      Pear     Peach  \\\n",
       "0  0.341002    0.315255  0.375852     0.292136  0.226278  0.804610  0.394865   \n",
       "1  0.537191    0.458828  0.452231     0.318448  0.311758  0.498060  0.416896   \n",
       "2  0.386674    0.406583  0.563667     0.379463  0.572559  0.469921  0.362688   \n",
       "3  0.335456    0.443824  0.618811     0.360106  0.405951  0.306371  0.328475   \n",
       "4  0.372083    0.387127  0.599096     0.349777  0.505208  0.452595  0.428940   \n",
       "\n",
       "     Orange     Lemon  LadyFinger  Cucumber      Corn  ChilliGreen    Cherry  \\\n",
       "0  0.309855  0.370026    0.237663  0.507296  0.162051     0.491359  0.250759   \n",
       "1  0.806128  0.385563    0.552115  0.500968  0.252959     0.410454  0.264638   \n",
       "2  0.276406  0.383648    0.456395  0.460107  0.364422     0.535779  0.274900   \n",
       "3  0.465907  0.414677    0.951618  0.457385  0.420880     0.565803  0.302666   \n",
       "4  0.441945  0.455679    0.711824  0.399981  0.255603     0.297288  0.290908   \n",
       "\n",
       "     Carrot  CapsicumGreen  Broccoli   Brinjal     Apple    Banana  \n",
       "0  0.440752       0.580714  0.348162  0.383197  0.525455  0.534317  \n",
       "1  0.461590       0.356402  0.362346  0.416804  0.444392  0.520542  \n",
       "2  0.552798       0.535719  0.250374  0.461672  0.504270  0.666670  \n",
       "3  0.620328       0.502862  0.269386  0.312841  0.373471  0.384275  \n",
       "4  0.653533       0.509162  0.321159  0.353953  0.288864  0.592705  "
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfile = open('ssim_.txt', 'a')\n",
    "tfile.write(df_final.to_string())\n",
    "tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
