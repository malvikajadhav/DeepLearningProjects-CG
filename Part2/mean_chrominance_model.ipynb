{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models \n",
    "import torch.optim as optim \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (0.19.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (2.8.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (2022.10.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (2.22.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from scikit-image) (1.7.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/akshaysharma/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from packaging>=20.0->scikit-image) (3.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join('./Dataset/face_images')\n",
    "aug_dir = os.path.join('./Dataset/augment_images')\n",
    "lab_dir = os.path.join('./Dataset/lab_images')\n",
    "l_dir = os.path.join('./Dataset/l_images')\n",
    "a_dir = os.path.join('./Dataset/a_images')\n",
    "b_dir = os.path.join('./Dataset/b_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_values = []\n",
    "image_list = glob.glob(os.path.join(a_dir,\"*.jpg\"))\n",
    "for i in image_list:\n",
    "        image = plt.imread(i)\n",
    "        a_values = np.append(a_values,image.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_values = []\n",
    "image_list = glob.glob(os.path.join(b_dir,\"*.jpg\"))\n",
    "image_list.sort()\n",
    "for i in image_list:\n",
    "        image = plt.imread(i)\n",
    "        b_values = np.append(b_values,image.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "a_values = NormalizeData(a_values)\n",
    "b_values = NormalizeData(b_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(list1, list2):\n",
    "      \n",
    "    merged_list = [[list1[i], list2[i]] for i in range(0, len(list1))]\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = merge(a_values,b_values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_image_list = glob.glob(os.path.join(l_dir,\"*.jpg\"))\n",
    "input_image_list.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean chrominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.cnn = nn.Sequential(nn.Conv2d(1,3,kernel_size=2, padding=0,stride=2),\n",
    "                                 nn.ReLU(),\n",
    "                                        nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(3,3,kernel_size=2, padding=0,stride=2),\n",
    "                                        nn.ReLU())\n",
    "        self.regressor = nn.Linear(3,2)                               \n",
    "                                 \n",
    "    def forward(self, input):\n",
    "        output = self.cnn(input)\n",
    "        output = output.flatten()\n",
    "        mean_chrominance = self.regressor(output)\n",
    "        return  mean_chrominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(3, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (13): ReLU()\n",
       "  )\n",
       "  (regressor): Linear(in_features=3, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = CNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013456131064227507\n",
      "0.012503337131130889\n",
      "0.01248067472119268\n",
      "0.012480676998275594\n",
      "0.012480676998275594\n",
      "0.012480676998275594\n",
      "0.012480676998275594\n",
      "0.012480676998275594\n",
      "0.012480676998275594\n",
      "0.012480676998275594\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "import torchvision.transforms as transforms\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "predictions = []\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for index in range(len(input_image_list)):\n",
    "        img_path =  input_image_list[index]\n",
    "        image = plt.imread(img_path)\n",
    "        mean, std = image.mean(), image.std()\n",
    "        image = trans(image)\n",
    "        y_label = torch.Tensor(y_labels[index]) \n",
    "        data = image.to(device=device)\n",
    "        targets = y_label.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        pred = model(data)\n",
    "        predictions.append(pred)\n",
    "        loss_val = loss(pred, targets)\n",
    "        \n",
    "        losses.append(loss_val.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005302971694618464\n",
      "tensor([-0.0477,  0.4015], grad_fn=<AddBackward0>)\n",
      "0.5981083676626149\n",
      "0.7988074740363509\n"
     ]
    }
   ],
   "source": [
    "print(losses[3])\n",
    "print(predictions[3])\n",
    "print(a_values[3])\n",
    "print(b_values[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
